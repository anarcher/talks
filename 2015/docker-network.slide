Multi-Host networking with Docker
OpenContainer Korea 2015
5 Sep 2015

anarcher
anarcher@gmail.com

* Multi-Host networking with docker 

.image docker-network/docker-turtles-communication.jpg

* Demo

- 아직은 실험적인 빌드(Experimental build) 에서만 사용가능
- docker engine 1.7 / dockercon 2015 에서 발표됨.
- docker engine 1.9에서는?


* Docker container linking

.image docker-network/my-small-idea.png

* Docker network UI

.code docker-network/network-ui.sh

네트웍을 만들거나,삭제하거나,조회할수 있다 

    docker network create -d <plugin_name> foo

    $ docker network create foo
    aae601f43744bc1f57c515a16c8c7c4989a2cad577978a32e6910b799a6bccf6
    $ docker network create -d overlay bar
    d9989793e2f5fe400a58ef77f706d03f668219688ee989ea68ea78b990fa2406

* Docker service UI

.code docker-network/service-ui.sh

`docker run`  할때 `--publish-service` 옵션을 사용하거나,

    docker run -itd --publish-service db.foo postgres

`docker service publish` 와 `docker service attach` 으로 container와 service(endpoint)을 연결 할수 있다

    $ docker service publish my-service.foo
    ec56fd74717d00f968c26675c9a77707e49ae64b8e54832ebf78888eb116e428
    $ docker service attach a0ebc12d3e48 my-service.foo


* Docker daemon & libkv 

- docker-machine create

    docker-machine --debug create \
        -d virtualbox \
        --virtualbox-boot2docker-url=https://github.com/anarcher/boot2docker-experimental/releases/download/1.9/boot2docker-1.9.iso \
        --engine-opt="kv-store=consul:$(docker-machine ip infra):8500" \
        --engine-label="com.docker.network.driver.overlay.bind_interface=eth1" \
        --engine-label="com.docker.network.driver.overlay.neighbor_ip=$(docker-machine ip demo0)" demo1

- docker daemon 

    docker daemon 
        --kv-store=consul:consul-host:8500 \ 
        --label=com.docker.network.driver.overlay.bind_interface=eth1 \
        --label=com.docker.network.driver.overlay.neighbor_ip=10.254.101.21

- cluster membership 을 위해서 serf([[http://serfdom.io]])을 사용 
- docker network,docker service의 metadata을 저장하기 위해서 docker/libkv(--kv-store)를 사용 
 
* Overlay network driver

- VXLAN(Virtual eXtensible Local Area Network) 사용 
    - Linux (3.7)지원 
    - L3 Networks상에서 (논리적인) L2 Network을 구성 
    - IP/UDP를 이용해서 encapsulation 하는 구조 
- 다른 네트웍 노드(docker engine)을 찾기 위해 serf([[http://serfdom.io]])을 사용 
- Linux netns(network namespace) 사용 
    - namespace 마다 독자적인 network 환경을 가질수 있다 
    - /var/run/docker/netns/

* docker/libnetwork

- Docker engine에서 network 부분을 분리 (docker engine도 libnetwork의 사용자 중..)
- CNM(Container Network Model)에 대한 구현 
- Docker engine에서 사용하는 host,bridge에 대한 구현도 이제는 docker/libnetwork에서
- Driver based networking  (builtin driver도 있고,remote driver도 사용할수 있다)

.image docker-network/docker-libnetwork.png _ 800

* CNM : Container Network Model 

.image docker-network/cnm-model.jpg _ 600

- Sandbox : 컨테이너를 위한 격리된 네트웍 환경 
    - IP,MAC,Route,DNS ; Linux netns,FreeBSD Jail
- Endpoint : 특정 네트워크에서 통신하는 네트웍 인터페이스. 
    - 컨테이너의 생성과 소멸과는 독립적으로 분리되어 Endpoint만의 생성과 소멸을 가진다 
- Network : 서로 통신할수 있는 여러 Endpoints의 그룹 
    - 하나의 endpoint는 하나의 network에만 속할수 있다. 

* Remote network driver plugin

- JSON/RPC/HTTP

- Plugin discovery
    - /etc/docker/plugin/[name].spec|.sock|.json
    
- API
    - /Plugin.Activate
    - /NetworkDriver.CreateNetwork
    - /NetworkDriver.DeleteNetwork
    - /NetworkDriver.CreateEndpoint
    - /NetworkDriver.EndpointOperInfo
    - /NetworkDriver.DeleteEndpoint
    - /NetworkDriver.Join
    - /NetworkDriver.Leave


